# VAE-based Anomaly Detection Module

## ğŸ“‹ Vue d'ensemble

Ce module implÃ©mente un systÃ¨me de dÃ©tection d'anomalies basÃ© sur un **Variational Autoencoder (VAE)** pour complÃ©ter le pipeline de classification des mÃ©lanomes.

### Pourquoi cette approche ?

L'approche VAE **renverse le problÃ¨me de classification** :
- Au lieu d'apprendre Ã  quoi ressemble un cancer, on apprend ce qu'est la **"normalitÃ©"** (lÃ©sions bÃ©nignes)
- Tout ce qui s'Ã©loigne trop de cette normalitÃ© est signalÃ© comme **anomalie**

### Avantages

1. **IndÃ©pendance vis-Ã -vis des donnÃ©es rares** : Pas besoin de nombreux exemples de mÃ©lanomes
2. **Filet de sÃ©curitÃ© Out-of-Distribution (OOD)** : DÃ©tecte les cas jamais vus Ã  l'entraÃ®nement
3. **ComplÃ©mentaire au classificateur supervisÃ©** : RÃ©duit les faux nÃ©gatifs critiques

---

## ğŸ”— Synergies avec le Pipeline Global

Ce module ne remplace pas le DenseNet, il le **renforce** via 3 synergies clÃ©s:

### âœ… Synergie 1: Triage PrÃ©liminaire (IMPLÃ‰MENTÃ‰)

Le systÃ¨me fonctionne en deux temps:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Image     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     Anomalie?
â”‚   VAE Check     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–º OUI â”€â”€â–º âš ï¸  PrioritÃ© HAUTE pour dermatologue
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    (quelle que soit l'avis du DenseNet)
          â”‚
          â”‚ NON (Normal)
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DenseNet Clf    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–º Classification standard
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Code:**
```python
from anomaly_detection import HybridClassifier

hybrid = HybridClassifier(
    vae_model_path='vae_output/best_model.pth',
    classifier_model_path='models/densenet.pth',
    fusion_strategy='cascade'  # â† Triage prÃ©liminaire
)
```

### âœ… Synergie 2: XAI et Cartes d'Erreur (IMPLÃ‰MENTÃ‰)

Le VAE offre une **explicabilitÃ© native** via les heatmaps d'anomalie:

```python
# GÃ©nÃ©rer les heatmaps d'anomalie
fig, heatmaps = detector.generate_anomaly_heatmaps(
    images=test_images,
    colormap='hot'
)

# Superposer sur l'image originale (trÃ¨s intuitif pour les mÃ©decins)
overlay, score = detector.generate_overlay_heatmap(
    image=lesion_image,
    alpha=0.5
)
```

**Visualisation:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Original   â”‚ Reconstructionâ”‚ Heatmap Anomalieâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     ğŸ”µ      â”‚      ğŸ”µ      â”‚     [COOL]      â”‚  â† Zone normale
â”‚    ğŸ”´ğŸ”´     â”‚     ğŸ”µğŸ”µ     â”‚   [ğŸ”¥ HOT]      â”‚  â† Zone pathologique
â”‚     ğŸ”µ      â”‚      ğŸ”µ      â”‚     [COOL]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

La heatmap montre **exactement** les zones que le VAE ne peut pas reconstruire!

### âœ… Synergie 3: Utilisation du DDPM (IMPLÃ‰MENTÃ‰)

Si vous manquez de donnÃ©es bÃ©nignes variÃ©es, utilisez le **DDPM existant** pour gÃ©nÃ©rer plus de donnÃ©es d'entraÃ®nement saines:

```bash
# 1. GÃ©nÃ©rer 1000 images bÃ©nignes avec DDPM
python anomaly_detection/ddpm_benign_augmentation.py \
    --ddpm_model_path generators/ddpm/checkpoints/best_model.pth \
    --num_samples 1000 \
    --quality_filter \
    --output_dir ./benign_augmented

# 2. Combiner avec les vraies donnÃ©es (70% rÃ©el, 30% synthÃ©tique)
python anomaly_detection/ddpm_benign_augmentation.py \
    --ddpm_model_path generators/ddpm/checkpoints/best_model.pth \
    --num_samples 500 \
    --real_data_dir ./data/benign_real \
    --synthetic_ratio 0.3 \
    --combined_output_dir ./benign_combined

# 3. EntraÃ®ner le VAE sur le dataset enrichi
python anomaly_detection/train_vae.py \
    --img_dir ./benign_combined \
    --epochs 100
```

**Avantage:** VAE plus robuste Ã  la diversitÃ© normale de la peau (diffÃ©rents types de peau, Ã©clairages, Ã¢ges, etc.)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        IMAGE D'ENTRÃ‰E                            â”‚
â”‚                         (128Ã—128Ã—3)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ENCODEUR (CNN)                           â”‚
â”‚  Conv2d(3â†’32) â†’ Conv2d(32â†’64) â†’ Conv2d(64â†’128) â†’ Conv2d(128â†’256) â”‚
â”‚                      + BatchNorm + LeakyReLU                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ESPACE LATENT                               â”‚
â”‚            Î¼ (mean) â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€ log(ÏƒÂ²) (log variance)          â”‚
â”‚                          â”‚                                       â”‚
â”‚              z = Î¼ + Ïƒ Ã— Îµ  (Reparameterization Trick)          â”‚
â”‚                     dim = 256                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DÃ‰CODEUR (CNNâ»Â¹)                          â”‚
â”‚  ConvT(256â†’128) â†’ ConvT(128â†’64) â†’ ConvT(64â†’32) â†’ ConvT(32â†’3)    â”‚
â”‚                      + BatchNorm + LeakyReLU                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMAGE RECONSTRUITE                            â”‚
â”‚                         (128Ã—128Ã—3)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Fonction de Perte

$$\mathcal{L} = \mathcal{L}_{\text{reconstruction}} + \beta \cdot D_{KL}$$

### Perte de Reconstruction (MSE)
$$\mathcal{L}_{\text{reconstruction}} = \frac{1}{N} \sum_{i=1}^{N} (x_i - \hat{x}_i)^2$$

Force le modÃ¨le Ã  bien recrÃ©er les images saines.

### Divergence KL
$$D_{KL} = -\frac{1}{2} \sum_{j=1}^{d} \left(1 + \log(\sigma_j^2) - \mu_j^2 - \sigma_j^2\right)$$

RÃ©gularise l'espace latent vers une distribution normale standard $\mathcal{N}(0, I)$.

---

## ğŸš€ Utilisation

### 1. EntraÃ®nement du VAE (uniquement sur images bÃ©nignes)

```bash
python train_vae.py \
    --img_dir ./data/isic2016/benign \
    --epochs 100 \
    --batch_size 32 \
    --latent_dim 256 \
    --beta 1.0 \
    --output_dir ./vae_output
```

### 2. Calibrage du Seuil

```python
from inference_vae import VAEAnomalyDetector

# Charger le modÃ¨le
detector = VAEAnomalyDetector(model_path='vae_output/checkpoints/best_model.pth')

# Calibrer sur un jeu de validation mixte
detector.calibrate(
    val_dataloader=val_loader,
    labels=val_labels,  # 0=bÃ©nin, 1=malin
    percentile=95.0,    # Seuil au 95Ã¨me percentile des bÃ©nins
    method='percentile'
)

# Visualiser la distribution des erreurs
detector.plot_error_distribution(
    errors_benign=benign_errors,
    errors_malignant=malignant_errors,
    save_path='error_distribution.png'
)
```

### 3. InfÃ©rence

```python
# PrÃ©dire pour un batch
predictions, anomaly_scores = detector.predict(images)

# PrÃ©dire pour une seule image
result = detector.predict_single(image_path='lesion.jpg')
print(f"Anomaly: {result['is_anomaly']}, Score: {result['anomaly_score']:.4f}")
```

### 4. Classificateur Hybride (VAE + DenseNet)

```python
from hybrid_classifier import HybridClassifier

# CrÃ©er le classificateur hybride
hybrid = HybridClassifier(
    vae_model_path='vae_output/checkpoints/best_model.pth',
    classifier_model_path='models/densenet_best.pth',
    fusion_strategy='weighted'  # ou 'voting', 'cascade', 'ensemble'
)

# Calibrer
hybrid.calibrate(val_loader, val_labels)

# PrÃ©dire
predictions, details = hybrid.predict(test_loader, return_details=True)

# Ã‰valuer
metrics = hybrid.evaluate(test_loader, test_labels)
print(f"Accuracy: {metrics['accuracy']:.4f}")
print(f"Improvement over classifier alone: {metrics['improvement_over_classifier']:.4f}")
```

---



1. Passer les images de validation dans le VAE
2. Calculer l'erreur de reconstruction (MSE) pour chaque image
3. Tracer la distribution des erreurs
4. Fixer le seuil entre les deux groupes (ex: 95Ã¨me percentile des bÃ©nins)

---

## ğŸ“ Structure des Fichiers

```
anomaly_detection/
â”œâ”€â”€ __init__.py              # Exports du module
â”œâ”€â”€ VAE_model.py             # Architecture du VAE
â”œâ”€â”€ train_vae.py             # Script d'entraÃ®nement
â”œâ”€â”€ inference_vae.py         # InfÃ©rence et calibrage
â”œâ”€â”€ hybrid_classifier.py     # Fusion VAE + DenseNet
â””â”€â”€ README.md                # Cette documentation
```

---

## âš™ï¸ Configuration

### VAEConfig

| ParamÃ¨tre | DÃ©faut | Description |
|-----------|--------|-------------|
| `image_size` | 128 | Taille des images en entrÃ©e |
| `latent_dim` | 256 | Dimension de l'espace latent |
| `hidden_dims` | [32, 64, 128, 256, 512] | Dimensions des couches cachÃ©es |
| `beta` | 1.0 | Coefficient KL (Î²-VAE) |
| `learning_rate` | 1e-4 | Taux d'apprentissage |
| `batch_size` | 32 | Taille des batchs |
| `dropout` | 0.2 | Taux de dropout |

---

## ğŸ“ˆ MÃ©triques d'Ã‰valuation

Le module calcule automatiquement :

- **Accuracy** : PrÃ©cision globale
- **Sensitivity (Recall)** : Taux de vrais positifs (malins correctement dÃ©tectÃ©s)
- **Specificity** : Taux de vrais nÃ©gatifs (bÃ©nins correctement identifiÃ©s)
- **Precision** : PrÃ©cision des prÃ©dictions positives
- **F1-Score** : Moyenne harmonique precision/recall
- **ROC-AUC** : Aire sous la courbe ROC
- **PR-AUC** : Aire sous la courbe Precision-Recall

---

## ğŸ”¬ StratÃ©gies de Fusion

| StratÃ©gie | Description | Usage recommandÃ© |
|-----------|-------------|------------------|
| `voting` | Vote majoritaire (OR) | Maximiser le rappel |
| `weighted` | Moyenne pondÃ©rÃ©e | Ã‰quilibre precision/recall |
| `cascade` | VAE en premier filtre | DÃ©tection OOD prioritaire |
| `ensemble` | Combinaison avec boost | Performance optimale |

---

## ğŸ“š RÃ©fÃ©rences

- Kingma, D. P., & Welling, M. (2014). Auto-Encoding Variational Bayes
- Higgins, I., et al. (2017). Î²-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework
- An, J., & Cho, S. (2015). Variational Autoencoder based Anomaly Detection using Reconstruction Probability
