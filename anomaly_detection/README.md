# VAE-based Anomaly Detection Module

## ğŸ“‹ Vue d'ensemble

Ce module implÃ©mente un systÃ¨me de dÃ©tection d'anomalies basÃ© sur un **Variational Autoencoder (VAE)** pour complÃ©ter le pipeline de classification des mÃ©lanomes.

### Pourquoi cette approche ?

L'approche VAE **renverse le problÃ¨me de classification** :
- Au lieu d'apprendre Ã  quoi ressemble un cancer, on apprend ce qu'est la **"normalitÃ©"** (lÃ©sions bÃ©nignes)
- Tout ce qui s'Ã©loigne trop de cette normalitÃ© est signalÃ© comme **anomalie**

### Avantages

1. **IndÃ©pendance vis-Ã -vis des donnÃ©es rares** : Pas besoin de nombreux exemples de mÃ©lanomes
2. **Filet de sÃ©curitÃ© Out-of-Distribution (OOD)** : DÃ©tecte les cas jamais vus Ã  l'entraÃ®nement
3. **ComplÃ©mentaire au classificateur supervisÃ©** : RÃ©duit les faux nÃ©gatifs critiques

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        IMAGE D'ENTRÃ‰E                            â”‚
â”‚                         (128Ã—128Ã—3)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ENCODEUR (CNN)                           â”‚
â”‚  Conv2d(3â†’32) â†’ Conv2d(32â†’64) â†’ Conv2d(64â†’128) â†’ Conv2d(128â†’256) â”‚
â”‚                      + BatchNorm + LeakyReLU                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ESPACE LATENT                               â”‚
â”‚            Î¼ (mean) â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€ log(ÏƒÂ²) (log variance)          â”‚
â”‚                          â”‚                                       â”‚
â”‚              z = Î¼ + Ïƒ Ã— Îµ  (Reparameterization Trick)          â”‚
â”‚                     dim = 256                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DÃ‰CODEUR (CNNâ»Â¹)                          â”‚
â”‚  ConvT(256â†’128) â†’ ConvT(128â†’64) â†’ ConvT(64â†’32) â†’ ConvT(32â†’3)    â”‚
â”‚                      + BatchNorm + LeakyReLU                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMAGE RECONSTRUITE                            â”‚
â”‚                         (128Ã—128Ã—3)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Fonction de Perte

$$\mathcal{L} = \mathcal{L}_{\text{reconstruction}} + \beta \cdot D_{KL}$$

### Perte de Reconstruction (MSE)
$$\mathcal{L}_{\text{reconstruction}} = \frac{1}{N} \sum_{i=1}^{N} (x_i - \hat{x}_i)^2$$

Force le modÃ¨le Ã  bien recrÃ©er les images saines.

### Divergence KL
$$D_{KL} = -\frac{1}{2} \sum_{j=1}^{d} \left(1 + \log(\sigma_j^2) - \mu_j^2 - \sigma_j^2\right)$$

RÃ©gularise l'espace latent vers une distribution normale standard $\mathcal{N}(0, I)$.

---

## ğŸš€ Utilisation

### 1. EntraÃ®nement du VAE (uniquement sur images bÃ©nignes)

```bash
python train_vae.py \
    --img_dir ./data/isic2016/benign \
    --epochs 100 \
    --batch_size 32 \
    --latent_dim 256 \
    --beta 1.0 \
    --output_dir ./vae_output
```

### 2. Calibrage du Seuil

```python
from inference_vae import VAEAnomalyDetector

# Charger le modÃ¨le
detector = VAEAnomalyDetector(model_path='vae_output/checkpoints/best_model.pth')

# Calibrer sur un jeu de validation mixte
detector.calibrate(
    val_dataloader=val_loader,
    labels=val_labels,  # 0=bÃ©nin, 1=malin
    percentile=95.0,    # Seuil au 95Ã¨me percentile des bÃ©nins
    method='percentile'
)

# Visualiser la distribution des erreurs
detector.plot_error_distribution(
    errors_benign=benign_errors,
    errors_malignant=malignant_errors,
    save_path='error_distribution.png'
)
```

### 3. InfÃ©rence

```python
# PrÃ©dire pour un batch
predictions, anomaly_scores = detector.predict(images)

# PrÃ©dire pour une seule image
result = detector.predict_single(image_path='lesion.jpg')
print(f"Anomaly: {result['is_anomaly']}, Score: {result['anomaly_score']:.4f}")
```

### 4. Classificateur Hybride (VAE + DenseNet)

```python
from hybrid_classifier import HybridClassifier

# CrÃ©er le classificateur hybride
hybrid = HybridClassifier(
    vae_model_path='vae_output/checkpoints/best_model.pth',
    classifier_model_path='models/densenet_best.pth',
    fusion_strategy='weighted'  # ou 'voting', 'cascade', 'ensemble'
)

# Calibrer
hybrid.calibrate(val_loader, val_labels)

# PrÃ©dire
predictions, details = hybrid.predict(test_loader, return_details=True)

# Ã‰valuer
metrics = hybrid.evaluate(test_loader, test_labels)
print(f"Accuracy: {metrics['accuracy']:.4f}")
print(f"Improvement over classifier alone: {metrics['improvement_over_classifier']:.4f}")
```

---

## ğŸ“Š Processus de Calibrage du Seuil

```
Distribution des Erreurs de Reconstruction
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                        â”‚
â”‚    â–ˆâ–ˆâ–ˆâ–ˆ                                               â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     BÃ©nins                    Malins         â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   (erreurs                  (erreurs        â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   faibles)                  Ã©levÃ©es)       â”‚
â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              â–ˆâ–ˆ           â”‚
â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          â–ˆâ–ˆâ–ˆâ–ˆ           â”‚
â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          â”‚
â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                      â”‚                                â”‚
â”‚                   SEUIL                               â”‚
â”‚            (95Ã¨me percentile)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. Passer les images de validation dans le VAE
2. Calculer l'erreur de reconstruction (MSE) pour chaque image
3. Tracer la distribution des erreurs
4. Fixer le seuil entre les deux groupes (ex: 95Ã¨me percentile des bÃ©nins)

---

## ğŸ“ Structure des Fichiers

```
anomaly_detection/
â”œâ”€â”€ __init__.py              # Exports du module
â”œâ”€â”€ VAE_model.py             # Architecture du VAE
â”œâ”€â”€ train_vae.py             # Script d'entraÃ®nement
â”œâ”€â”€ inference_vae.py         # InfÃ©rence et calibrage
â”œâ”€â”€ hybrid_classifier.py     # Fusion VAE + DenseNet
â””â”€â”€ README.md                # Cette documentation
```

---

## âš™ï¸ Configuration

### VAEConfig

| ParamÃ¨tre | DÃ©faut | Description |
|-----------|--------|-------------|
| `image_size` | 128 | Taille des images en entrÃ©e |
| `latent_dim` | 256 | Dimension de l'espace latent |
| `hidden_dims` | [32, 64, 128, 256, 512] | Dimensions des couches cachÃ©es |
| `beta` | 1.0 | Coefficient KL (Î²-VAE) |
| `learning_rate` | 1e-4 | Taux d'apprentissage |
| `batch_size` | 32 | Taille des batchs |
| `dropout` | 0.2 | Taux de dropout |

---

## ğŸ“ˆ MÃ©triques d'Ã‰valuation

Le module calcule automatiquement :

- **Accuracy** : PrÃ©cision globale
- **Sensitivity (Recall)** : Taux de vrais positifs (malins correctement dÃ©tectÃ©s)
- **Specificity** : Taux de vrais nÃ©gatifs (bÃ©nins correctement identifiÃ©s)
- **Precision** : PrÃ©cision des prÃ©dictions positives
- **F1-Score** : Moyenne harmonique precision/recall
- **ROC-AUC** : Aire sous la courbe ROC
- **PR-AUC** : Aire sous la courbe Precision-Recall

---

## ğŸ”¬ StratÃ©gies de Fusion

| StratÃ©gie | Description | Usage recommandÃ© |
|-----------|-------------|------------------|
| `voting` | Vote majoritaire (OR) | Maximiser le rappel |
| `weighted` | Moyenne pondÃ©rÃ©e | Ã‰quilibre precision/recall |
| `cascade` | VAE en premier filtre | DÃ©tection OOD prioritaire |
| `ensemble` | Combinaison avec boost | Performance optimale |

---

## ğŸ“š RÃ©fÃ©rences

- Kingma, D. P., & Welling, M. (2014). Auto-Encoding Variational Bayes
- Higgins, I., et al. (2017). Î²-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework
- An, J., & Cho, S. (2015). Variational Autoencoder based Anomaly Detection using Reconstruction Probability
